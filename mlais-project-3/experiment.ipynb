{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "72db7199-7220-434e-a46c-d9a708b90bb3",
      "cell_type": "code",
      "source": "import numpy as np\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nimport random",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "id": "72d55abb-4fcf-4f0a-bb3a-8aef3dc568e8",
      "cell_type": "code",
      "source": "\"\"\"\n    Multi-Class Perceptron using One-vs-All (OvA) strategy.\n\"\"\"\nclass MultiClassPerceptron:\n\n    def __init__(self, alpha=0.01):\n        \"\"\"\n        Initialize the multi-class perceptron model.\n        :param alpha: Learning rate (positive float).\n        \"\"\"\n        if alpha <= 0:\n            raise ValueError(\"Learning rate should be positive.\")\n        \n        self.alpha = alpha  # Learning rate\n        self.num_classes = None  # Number of classes (to be initialized during training)\n        self.weights = None  # Weights for each class\n        self.biases = None  # Biases for each class\n\n    def train(self, X, y, epochs=10):\n        \"\"\"\n        Train the multi-class perceptron using the one-vs-rest strategy.\n        :param X: NxD numpy array, input features (N samples, D features).\n        :param y: Nx1 numpy array, class labels (integer values from 0 to C-1).\n        :param epochs: Number of iterations over the training data.\n        \"\"\"\n        # Validate inputs\n        if X.size == 0 or y.size == 0:\n            raise ValueError(\"Input data X and y cannot be empty.\")\n        if X.shape[0] != y.shape[0]:\n            raise ValueError(\"Number of samples in X and y must match.\")\n        if epochs <= 0:\n            raise ValueError(\"Number of epochs should be positive.\")\n        \n        # Determine the number of classes\n        self.num_classes = len(np.unique(y))\n        n_samples, n_features = X.shape\n\n        # Initialize weights and biases for each class\n        self.weights = np.zeros((self.num_classes, n_features))  # Shape: (C, D)\n        self.biases = np.zeros(self.num_classes)  # Shape: (C,)\n\n        # Training loop\n        for epoch in range(epochs):\n            for i in range(n_samples):\n                X_i = X[i]\n                y_i = y[i]\n\n                # Compute the scores for all classes\n                scores = np.dot(self.weights, X_i) + self.biases\n\n                # Predicted class (highest score)\n                y_pred = np.argmax(scores)\n\n                # Update weights and biases if misclassified\n                if y_pred != y_i:\n                    # Penalize the wrong class\n                    self.weights[y_pred] -= self.alpha * X_i\n                    self.biases[y_pred] -= self.alpha\n\n                    # Reward the correct class\n                    self.weights[y_i] += self.alpha * X_i\n                    self.biases[y_i] += self.alpha\n\n    def predict(self, X_new):\n        \"\"\"\n        Predict the class labels for new samples.\n        :param X_new: MxD numpy array, input features for new samples (M samples, D features).\n        :return: Mx1 numpy array, predicted class labels.\n        \"\"\"\n        if self.weights is None or self.biases is None:\n            raise ValueError(\"The perceptron is not trained yet. Train it before predicting.\")\n\n        # Compute scores for all classes\n        scores = np.dot(X_new, self.weights.T) + self.biases\n        # Predict the class with the highest score\n        return np.argmax(scores, axis=1)\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "id": "90040aff-9e4b-4245-a657-fe38a79bd5bf",
      "cell_type": "code",
      "source": "\"\"\"\n    SAMME - Multi-class AdaBoost algorithm\n\"\"\"\nclass SAMME:\n\n    def __init__(self, num_learner: int, num_cats: int):\n        \"\"\"\n        Initialize the SAMME model.\n        :param num_learners: number of weak learners.\n        :param num_cats: number of class.\n        \"\"\"\n        if num_cats < 2:\n            raise ValueError(f\"num_cats should be at least 2, but got {num_cats}\")\n        self.num_learner = num_learner\n        self.num_cats = num_cats\n        self.entry_weights = None\n        self.learner_weights = None\n        self.sorted_learners = None\n\n    def get_num_learner(self):\n        return self.num_learner\n\n    def train(self, train_data: list, learners: list):\n        \"\"\"\n        Train the AdaBoost model.\n        :param train_data: List of (features, label) tuples.\n        :param learners: List of weak learner objects with a `predict(X)` method.\n        \"\"\"\n        print(\"Starting boosting...\")\n        n = len(train_data)\n        m = len(learners)\n\n        self.entry_weights = np.full(n, 1 / n, dtype=np.float32)\n        self.learner_weights = np.zeros(m, dtype=np.float32)\n        self.performance_metrics = []  # Store error rates for visualization\n\n        errors = []\n        for learner_idx, learner in enumerate(learners):\n            error = 0\n            for X, label in train_data:\n                if learner.predict(X.reshape(1, -1)) != label:\n                    error += 1\n            errors.append((learner, error))\n\n        # Sort learners by error\n        self.sorted_learners = [learner for learner, _ in sorted(errors, key=lambda x: x[1])]\n\n\n        # Boost each learner\n        for idx, learner in enumerate(self.sorted_learners):\n            # Compute weighted error\n            is_wrong = np.zeros((n,))\n            for entry_idx, entry in enumerate(train_data):\n                X, label = entry[0], int(entry[1])\n                predicted_cat = learner.predict(X.reshape(1, -1))\n                if predicted_cat != label:\n                    is_wrong[entry_idx] = 1\n            \n            # Clamp weighted_error to avoid invalid values\n            weighted_error = np.sum(is_wrong * self.entry_weights) / self.entry_weights.sum()\n            weighted_error = max(1e-6, min(1 - 1e-6, weighted_error))\n\n            self.performance_metrics.append(weighted_error)\n                        \n            # Compute alpha (learner weight)\n            self.learner_weights[idx] = max(0, np.log((1 - weighted_error) / weighted_error) + np.log(self.num_cats - 1))\n            \n            # Update entry weights\n            is_wrong = is_wrong.flatten()\n            self.entry_weights *= np.exp(self.learner_weights[idx] * is_wrong)\n            self.entry_weights /= self.entry_weights.sum()  # Normalize\n\n        self.learner_weights /= np.sum(self.learner_weights)\n        print(\"Boosting completed.\")\n\n    def predict(self, data):\n        \"\"\"\n        Predict the label for each sample in data.\n        :param data: List or array of features.\n        :return: Predicted class labels.\n        \"\"\"\n        pooled_predictions = np.zeros((len(data), self.num_cats), dtype=np.float32)\n        for idx, learner in enumerate(self.sorted_learners):\n            predictions = np.array([learner.predict(X.reshape(1, -1)) for X in data])\n            for i, pred in enumerate(predictions):\n                pooled_predictions[i, pred] += self.learner_weights[idx]\n        return np.argmax(pooled_predictions, axis=1)\n\n\n    def visualize_performance(self):\n        \"\"\"\n        Visualize the performance of each weak learner during training.\n        \"\"\"\n        plt.figure(figsize=(10, 6))\n        plt.plot(range(1, len(self.performance_metrics) + 1), self.performance_metrics, marker='o', label=\"Error Rate\")\n        plt.title(\"Performance of Weak Learners During Training\")\n        plt.xlabel(\"Iteration\")\n        plt.ylabel(\"Error Rate\")\n        plt.legend()\n        plt.grid(True)\n        plt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 87
    },
    {
      "id": "662195a8-4cd3-453b-871c-67cf07979fd3",
      "cell_type": "code",
      "source": "\"\"\"\nTrain weak learners separately.\n\"\"\"\ndef train_weak_learners(num_weak_learners, alpha, epochs, X_train, y_train):\n    \"\"\"\n    Train weak learners (perceptrons) with different alphas and return them.\n    :param num_weak_learners: Number of weak learners.\n    :param alpha: Learning rate for the perceptrons.\n    :param epochs: Number of epochs for training weak learners.\n    :param X_train: Training data features.\n    :param y_train: Training data labels.\n    :return: List of trained weak learners.\n    \"\"\"\n    print(\"Training weak learners...\")\n    weak_learners = []\n    alpha_min = 0.1 * alpha\n    alpha_max = 10 * alpha\n    total_accuracy = 0\n\n    for i in range(num_weak_learners):\n        learner = MultiClassPerceptron(alpha=random.uniform(alpha_min, alpha_max))\n        weak_learners.append(learner)\n\n        # Shuffle training data for each learner to ensure different weight updates\n        shuffled_indices = np.random.permutation(len(X_train))\n        X_train_shuffled = X_train[shuffled_indices]\n        y_train_shuffled = y_train[shuffled_indices]\n\n        # Train each weak learner\n        learner.train(X_train_shuffled, y_train_shuffled, epochs=epochs)\n\n        # Compute training accuracy for the current learner\n        predictions = learner.predict(X_train_shuffled)\n        accuracy = np.mean(predictions == y_train_shuffled)\n        total_accuracy += accuracy\n\n    # Compute and print the average training accuracy\n    average_accuracy = total_accuracy / num_weak_learners\n    print(f\"Average Training Accuracy of Weak Learners = {average_accuracy:.2f}\")\n\n    return weak_learners",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 57
    },
    {
      "id": "c1bf62fa-ba40-403b-abd7-2341a992811a",
      "cell_type": "code",
      "source": "def main():\n    # Load dataset\n    X, y = load_digits(return_X_y=True)\n    X = X / 16.0  # Normalize features\n\n    # Split data into training, validation, and test sets\n    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n\n    # Further split the training set for weak learners and AdaBoost\n    X_weak_train, X_boost_train, y_weak_train, y_boost_train = train_test_split(X_train, y_train, test_size=0.93, random_state=42)\n\n    # Define weak learner configuration\n    weak_learner_config = {\n        \"alpha\": 0.05,\n        \"epochs\": 1\n    }\n\n    # Define the list of number of weak learners to try\n    num_weak_learner_list = [20, 50, 100, 500, 1000]\n\n    best_accuracy = 0\n    best_model = None\n\n    # Iterate over the number of weak learners\n    for num_weak_learners in num_weak_learner_list:\n        print(f\"\\nTraining AdaBoost model with {num_weak_learners} weak learners...\")\n\n        # Train the weak learners for the current configuration\n        weak_learners = train_weak_learners(\n            num_weak_learners,\n            weak_learner_config[\"alpha\"],\n            weak_learner_config[\"epochs\"],\n            X_weak_train,\n            y_weak_train\n        )\n\n        # Initialize the AdaBoost model with the trained weak learners\n        num_classes = len(np.unique(y_boost_train))\n        model = SAMME(len(weak_learners), num_classes)\n\n        # Train the AdaBoost model\n        train_data = [(X_boost_train[i], y_boost_train[i]) for i in range(len(y_boost_train))]\n        model.train(train_data, weak_learners)\n\n        # Training error\n        y_train_pred = model.predict(X_boost_train)\n        accuracy = accuracy_score(y_boost_train, y_train_pred)\n        print(f\"Training accuracy: {accuracy * 100:.2f}%\")\n\n        # Validate the model\n        y_val_pred = model.predict(X_val)\n        accuracy = accuracy_score(y_val, y_val_pred)\n        print(f\"Validation accuracy: {accuracy * 100:.2f}%\")\n\n        # Keep track of the best model\n        if accuracy > best_accuracy:\n            best_accuracy = accuracy\n            best_model = model\n\n    # Test the best model\n    if best_model:\n        y_test_pred = best_model.predict(X_test)\n        test_accuracy = accuracy_score(y_test, y_test_pred)\n        print(f\"\\nBest model is the one with {best_model.get_num_learner()} learners:\")\n        print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")\n    else:\n        print(\"No model was selected.\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\nTraining AdaBoost model with 20 weak learners...\nTraining weak learners...\nAverage Training Accuracy of Weak Learners = 0.69\nStarting boosting...\nBoosting completed.\nTraining accuracy: 83.69%\nValidation accuracy: 79.44%\n\nTraining AdaBoost model with 50 weak learners...\nTraining weak learners...\nAverage Training Accuracy of Weak Learners = 0.64\nStarting boosting...\nBoosting completed.\nTraining accuracy: 85.94%\nValidation accuracy: 82.22%\n\nTraining AdaBoost model with 100 weak learners...\nTraining weak learners...\nAverage Training Accuracy of Weak Learners = 0.64\nStarting boosting...\nBoosting completed.\nTraining accuracy: 87.51%\nValidation accuracy: 83.89%\n\nTraining AdaBoost model with 500 weak learners...\nTraining weak learners...\nAverage Training Accuracy of Weak Learners = 0.63\nStarting boosting...\nBoosting completed.\nTraining accuracy: 88.93%\nValidation accuracy: 86.11%\n\nTraining AdaBoost model with 1000 weak learners...\nTraining weak learners...\nAverage Training Accuracy of Weak Learners = 0.63\nStarting boosting...\nBoosting completed.\nTraining accuracy: 89.45%\nValidation accuracy: 88.89%\n\nTraining AdaBoost model with 3000 weak learners...\nTraining weak learners...\nAverage Training Accuracy of Weak Learners = 0.63\nStarting boosting...\nBoosting completed.\nTraining accuracy: 89.23%\nValidation accuracy: 86.67%\n\nBest model is the one with 1000 learners:\nTest accuracy: 92.78%\n"
        }
      ],
      "execution_count": 94
    },
    {
      "id": "f32be82f-cae6-422e-b547-e59774abfa12",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}